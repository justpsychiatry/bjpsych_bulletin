<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="editorial"><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 1.1?><?ConverterInfo.XSLTName jats2jats3.xsl?><?ConverterInfo.Version 1?><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">BJPsych Bull</journal-id><journal-id journal-id-type="iso-abbrev">BJPsych Bull</journal-id><journal-id journal-id-type="publisher-id">BJB</journal-id><journal-title-group><journal-title>BJPsych Bulletin</journal-title></journal-title-group><issn pub-type="ppub">2056-4694</issn><issn pub-type="epub">2056-4708</issn><publisher><publisher-name>Cambridge University Press</publisher-name><publisher-loc>Cambridge, UK</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">8914921</article-id><article-id pub-id-type="pmid">33752773</article-id><article-id pub-id-type="doi">10.1192/bjb.2021.23</article-id><article-id pub-id-type="pii">S2056469421000231</article-id><article-categories><subj-group subj-group-type="topic"><subject>Education</subject></subj-group><subj-group subj-group-type="heading"><subject>Praxis</subject></subj-group></article-categories><title-group><article-title>Transforming MRCPsych theory examinations: digitisation and very short answer questions (VSAQs)</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-5194-2204</contrib-id><name><surname>Scheeres</surname><given-names>Karl</given-names></name><xref rid="aff1" ref-type="aff">1</xref></contrib><contrib contrib-type="author"><name><surname>Agrawal</surname><given-names>Niruj</given-names></name><xref rid="aff2" ref-type="aff">2</xref><xref rid="aff3" ref-type="aff">3</xref></contrib><contrib contrib-type="author"><name><surname>Ewen</surname><given-names>Stephanie</given-names></name><xref rid="aff4" ref-type="aff">4</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Hall</surname><given-names>Ian</given-names></name><xref rid="aff5" ref-type="aff">5</xref><xref rid="cor1" ref-type="corresp"/></contrib></contrib-group><aff id="aff1"><label>1</label><institution>Centre for Health Sciences Education, University of Bristol</institution>, <country>UK</country></aff><aff id="aff2"><label>2</label><institution>St George's Hospital</institution>, <country>UK</country></aff><aff id="aff3">
<label>3</label>
<institution>St George's, University of London, UK</institution>
</aff><aff id="aff4"><label>4</label><institution>South London and Maudsley NHS Foundation Trust</institution>, <country>UK</country></aff><aff id="aff5"><label>5</label><institution>East London NHS Foundation Trust</institution>, <country>UK</country></aff><author-notes><corresp id="cor1">Correspondence to Ian Hall (<email>ian.hall4@nhs.net</email>)</corresp></author-notes><pub-date publication-format="print" date-type="pub" iso-8601-date="2022-02"><month>2</month><year>2022</year></pub-date><volume>46</volume><issue seq="12">1</issue><fpage>52</fpage><lpage>56</lpage><history><date date-type="received"><day>09</day><month>9</month><year>2020</year></date><date date-type="rev-recd"><day>13</day><month>1</month><year>2021</year></date><date date-type="accepted"><day>12</day><month>2</month><year>2021</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2021</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>The Author(s)</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an Open Access article, distributed under the terms of the Creative Commons Attribution licence (<uri xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</uri>), which permits unrestricted re-use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xlink:title="pdf" xlink:href="S2056469421000231a.pdf"/><abstract abstract-type="normal"><p>Many examinations are now delivered online using digital formats, the migration to which has been accelerated by the COVID-19 pandemic. The MRCPsych theory examinations have been delivered in this way since Autumn 2020. The multiple choice question formats currently in use are highly reliable, but other formats enabled by the digital platform, such as very short answer questions (VSAQs), may promote deeper learning. Trainees often ask for a focus on core knowledge, and the absence of cueing with VSAQs could help achieve this. This paper describes the background and evidence base for VSAQs, and how they might be introduced. Any new question formats would be thoroughly piloted before appearing in the examinations and are likely to have a phased introduction alongside existing formats.</p></abstract><kwd-group><title>Keywords</title><kwd>Education and training</kwd><kwd>supervision</kwd><kwd>information technologies</kwd><kwd>cost-effectiveness</kwd><kwd>history of psychiatry</kwd></kwd-group><counts><table-count count="2"/><ref-count count="21"/><page-count count="5"/></counts></article-meta></front><body><p>Examinations are now being delivered on online platforms in many undergraduate and postgraduate contexts. The COVID-19 pandemic has accelerated this, as digital platforms have the potential to enable examination delivery during lockdowns, or if trainees are isolating or in quarantine, without social distancing concerns. Education is also becoming increasingly international, and the MRCPsych examination is both sought after and has been delivered in international centres for many years. However, travel to examination centres for both staff and candidates is expensive, and significantly increases its overall carbon footprint.</p><p>The Royal College of Psychiatrists has therefore decided to deliver its theory examinations via digital platforms as from Autumn 2020, using a combination of artificial intelligence and in-person online proctoring (equivalent to traditional invigilators) to ensure that high standards of probity are maintained. The examinations will initially be delivered using the two existing question formats, multiple choice questions (MCQs) and extended matching questions (EMQs). However, digital platforms enable the use of new question formats that may allow more comprehensive coverage of the syllabus (the syllabus can be found at: <uri xlink:href="https://www.rcpsych.ac.uk/training/exams/preparing-for-exams">https://www.rcpsych.ac.uk/training/exams/preparing-for-exams</uri>). We know that assessment has a powerful effect in driving learning,<sup><xref rid="ref1" ref-type="bibr">1</xref></sup> and multiple choice question formats may encourage rote learning from question banks. We will thoroughly evaluate any new question formats before we introduce them into the MRCPsych examination, but we would hope that they would encourage deeper and more holistic learning strategies that would better equip our future psychiatrists to have the biggest impact on the mental health of their patients.</p><sec sec-type="other" id="sec1"><title>Choosing examination formats for the MRCPsych</title><p>When setting an examination, some of the key factors<sup><xref rid="ref2" ref-type="bibr">2</xref></sup> that need to be considered when assessing its utility are shown in <xref rid="tab01" ref-type="table">Table 1</xref>. Each of these factors have to be weighed up against each other, with differing weightings according to the purpose and type of assessment.
<table-wrap position="float" id="tab01"><label>Table 1</label><caption><p>Key factors to be considered when assessing the utility of an assessment (adapted with permission from reference<sup><xref rid="ref2" ref-type="bibr">2</xref></sup>)</p></caption><alternatives><graphic xlink:href="S2056469421000231_tab1" position="float"/><table frame="hsides" rules="groups"><col align="left" width="1*" span="1"/><col align="left" width="1*" span="1"/><thead><tr><th align="left" colspan="1" rowspan="1">Factor</th><th align="left" colspan="1" rowspan="1">Questions asked</th></tr></thead><tbody><tr><td colspan="1" rowspan="1">Validity</td><td colspan="1" rowspan="1">Does the examination test what we want it to test?</td></tr><tr><td colspan="1" rowspan="1">Reliability</td><td colspan="1" rowspan="1">Are the results repeatable and accurate? Are external sources of error other than candidate ability accounted for and reduced?</td></tr><tr><td colspan="1" rowspan="1">Educational impact</td><td colspan="1" rowspan="1">What is the impact of the examination upon trainees&#x02019; learning? Does it lead to deeper learning and long-term retention?</td></tr><tr><td colspan="1" rowspan="1">Acceptability</td><td colspan="1" rowspan="1">Is the examination acceptable to those sitting it and other stakeholders?</td></tr><tr><td colspan="1" rowspan="1">Cost</td><td colspan="1" rowspan="1">Are costs reasonable?</td></tr></tbody></table></alternatives></table-wrap></p><p>MCQs are a format that lends itself to reliability through standardisation of answers and ease of evaluation of large numbers of candidates via machine marking. Although MCQs have been used since the inception of the MRCPsych in 1972, historically, short answer questions (SAQs) and essays were also utilised; these were phased out as individual marking of SAQs with increasing numbers of candidates was taxing, and there were questions about the reliability of essay marking.<sup><xref rid="ref3" ref-type="bibr">3</xref></sup> The format of MCQs evolved from initial true/false answers to the single best answer or &#x02018;best of five&#x02019; in use today, as well as the use of the EMQs, in which there is a theme, several stems and a greater number of options, more easily assessing the application of knowledge.<sup><xref rid="ref4" ref-type="bibr">4</xref></sup> The MRCPsych is a high-stakes examination, with important consequences for candidates, our patients and society in general. In common with all high-stakes postgraduate medical assessments based in the UK, it is regulated closely by the General Medical Council, and all changes to format and structure must undergo prospective approval by them.</p><p>Given these concerns, the reliability of the MRCPsych must be extremely high, so that no trainee passes without the requisite ability. Fortunately, the written papers have excellent reliability (with Cronbach's alpha, a measure of reliability, consistently &#x0003e;0.85), but some have questioned whether this has happened at the expense of validity.<sup><xref rid="ref5" ref-type="bibr">5</xref>,<xref rid="ref6" ref-type="bibr">6</xref></sup> Has the depth of clinical context and its application been lost? Perhaps we fail to reward those trainees who undertake in-depth study of complex issues, such as aetiology, ethics and the history of psychiatry.<sup><xref rid="ref5" ref-type="bibr">5</xref></sup> The main criticism of MCQs is a &#x02018;cueing&#x02019; effect, whereby candidates are cued by the correct answer, rather than actively recalling it.<sup><xref rid="ref7" ref-type="bibr">7</xref></sup> There is evidence that requiring candidates to <italic toggle="yes">construct</italic> an answer, such as in SAQs, produces better memory than tests that require recognition.<sup><xref rid="ref8" ref-type="bibr">8</xref></sup> Additional issues with MCQs may include various &#x02018;test-taking&#x02019; behaviours, such as eliminating wrong answers to arrive at the correct one, guessing from the options available and seeking clues from the language used to deduce the correct answer independently from the knowledge required.<sup><xref rid="ref9" ref-type="bibr">9</xref></sup></p><p>MCQs end up testing recognition memory, and recall is significantly affected by this cueing effect. Creating a good MCQ with valid and meaningful distractors (incorrect options) can be extremely hard. Poor-quality distractors can make guessing more rewarding. There are a number of areas of the syllabus where it is impossible to write valid distractors, and as a consequence, clinically meaningful knowledge may not be examined and more obscure areas, where MCQs may be easier to write, are more likely to be tested.</p><p>As mentioned above, it is intuitive and commonly recognised that the assessment drives learning.<sup><xref rid="ref1" ref-type="bibr">1</xref></sup> Areas of the syllabus that are more commonly examined are therefore more likely to be studied by trainees. Assessment factors contribute to strategies used to study,<sup><xref rid="ref10" ref-type="bibr">10</xref></sup> which could influence the trainees&#x02019; overall learning and the extent of knowledge achieved. Developments in technology have allowed easy access to online MCQ &#x02018;question banks&#x02019;. Many trainees therefore focus their effort on practicing these questions, rather than focusing on core learning and developing deeper understanding.</p><p>The costs of taking the MRCPsych for candidates are high<sup><xref rid="ref11" ref-type="bibr">11</xref></sup> because of the high cost of the infrastructure behind the examination, e.g. the professional examinations team, detailed psychometric analysis, and supporting the psychiatrists who volunteer their time freely to create and quality-assure questions, and analyse the results. For several years now, the examination is budgeted not to make excessive surpluses, but if this inadvertently happens, the surplus is directed to the trainees&#x02019; fund, which has previously funded the creation of the Trainees Online learning resource, among other projects. Moving to digital platforms may reduce costs to trainees as they no longer need travel or accommodation, and potentially could reduce overall costs as no physical venues are required; however, this is uncertain, and the costs of commercial contracts for software, training and ongoing IT support may counteract this.</p></sec><sec sec-type="other" id="sec2"><title>Digitisation of examinations</title><p>The COVID-19 pandemic led to a rapid and unpredicted introduction of online examinations for the MRCPsych, although the College had plans to begin moving toward digitisation before the pandemic. Although there is a relative paucity of literature on online examinations,<sup><xref rid="ref12" ref-type="bibr">12</xref></sup> one small study, in which a direct comparison of online examinations versus paper examinations was made, showed equivalent reliability and validity.<sup><xref rid="ref13" ref-type="bibr">13</xref></sup> In terms of candidate performance in online versus paper examinations, the few studies directly testing this have shown no significant differences.<sup><xref rid="ref13" ref-type="bibr">13</xref>,<xref rid="ref14" ref-type="bibr">14</xref></sup> Candidates&#x02019; perception of online examinations are often favourable, and one study found reduced anxiety when taking online compared with traditional paper-based examinations.<sup><xref rid="ref14" ref-type="bibr">14</xref></sup> Possibly, the fact that candidates are not able to see their peers might account for this. However, it is clear that the rapid introduction of digitisation for the MRCPsych caused considerable anxiety in trainees; the same study<sup><xref rid="ref14" ref-type="bibr">14</xref></sup> recognised that the first sitting of online examinations can cause anxiety, which later subsides with familiarity upon repeated testing.</p></sec><sec sec-type="other" id="sec3"><title>Very short answer questions</title><p>Very short answer questions (VSAQs) are a novel format of written questions.<sup><xref rid="ref15" ref-type="bibr">15</xref>&#x02013;<xref rid="ref19" ref-type="bibr">19</xref></sup> A VSAQ consists of a short question for which an answer is required to be manually entered on computer screen from free recall, as open text. There are no options provided to choose from as in MCQs/EMQs. Generally, the answer would be only a few words. <xref rid="box1" ref-type="boxed-text">Box 1</xref> shows some examples of how VSAQs may look. Any correct response will attract one mark and any incorrect response will attract zero marks. Examination software would be programmed to recognise multiple versions of correct answers, using smart algorithms. These would allow different versions of a correct response to be recognised. For example, the first question in <xref rid="box1" ref-type="boxed-text">Box 1</xref> provides an example of several possible correct answers for that question; all of these answers would attract a full mark, and centre around the idea of a reduction or suppression of the default mode network. The software would additionally be programmed to highlight any answer that is a non-exact match (approximate) to any possible correct answers, and these will be manually reviewed by a designated and trained examiner to ascertain whether that represents a correct response. This will ensure that any unforeseen versions of correct responses will not go unrecognised and unrewarded. That response will then be saved in the list of correct answers for that question for any future examinations. Examiners will also review all other marking done by the computer, to ensure accuracy. Minor spelling errors or typos (e.g. &#x02018;inihbited&#x02019; rather than &#x02018;inhibited&#x02019;) will not be penalised and will be picked up during the review process. VSAQs also allow for two entirely different but correct answers, as illustrated in the second example in <xref rid="box1" ref-type="boxed-text">Box 1</xref>. In this example, again, either of the responses will attract a full mark.
<boxed-text id="box1" position="float"><label>Box 1</label><caption><p>Very short answer question examples.</p></caption><p>Example 1: A very short answer question with different versions of the correct answer:</p><p>How does the &#x02018;default mode network&#x02019; react in a healthy brain when one performs a goal-directed task?</p><p>Correct answers may include, but are not limited to:
<list list-type="bullet"><list-item><p>Decreased activity</p></list-item><list-item><p>Reduced activity</p></list-item><list-item><p>Inhibited</p></list-item><list-item><p>Suppressed</p></list-item><list-item><p>Switched off</p></list-item></list></p><p>Example 2: A very short answer question with different correct answers:</p><p>Name the neurotransmitter mechanism thought to be responsible for clozapine-induced hypersalivation.</p><p>Correct answers would include:
<list list-type="bullet"><list-item><p>Alpha 2 receptor antagonism</p></list-item><list-item><p>Muscarinic M4 agonism</p></list-item></list></p><p>Again, differing versions of these correct answers would be accepted, e.g. a2 adrenergic antagonism.</p></boxed-text></p><p>The free recall tested by the VSAQs can be more easily focused on clinically relevant topics, and allow freedom to assess a wider spectrum of the syllabus where MCQs may be impossible to write. This should encourage trainees to refocus on core learning through textbooks and primary papers, and make their knowledge base more clinically relevant in the long term.</p><p>In the studies to date, VSAQs have been shown to have higher reliability than MCQs, and reduce the cueing effect.<sup><xref rid="ref15" ref-type="bibr">15</xref>&#x02013;<xref rid="ref17" ref-type="bibr">17</xref></sup> They may improve validity by testing nascent knowledge and clinical skills, rather than the ability to pass examinations.<sup><xref rid="ref15" ref-type="bibr">15</xref></sup> In one study of 300 medical students,<sup><xref rid="ref15" ref-type="bibr">15</xref></sup> 69% of students undertaking VSAQs felt that they were more representative of how they would be expected to answer questions in actual clinical practice, and about half felt that they would change their learning strategies in response. However, these studies were conducted on undergraduate medical students and may not be generalisable to postgraduate psychiatry trainees. Additionally, as far as we are aware, there has not been any published data that uses VSAQs from a high-stakes examination such as the MRCPsych, although at least one other College are considering their introduction for UK medical trainees.<sup><xref rid="ref20" ref-type="bibr">20</xref></sup> Finally, as VSAQs require recall rather than recognition, candidates appear to universally score lower in them when compared with MCQs;<sup><xref rid="ref15" ref-type="bibr">15</xref>&#x02013;<xref rid="ref19" ref-type="bibr">19</xref></sup> this must be carefully accounted for in the standard setting process that sets the pass mark, so that standard setting judges are aware of likely lower scores in comparison with MCQs, particularly in first iterations of the test when they are lacking comparative past data. To account for this, there would be pilot questions tested and a full analysis undertaken to inform future standard setting.</p></sec><sec sec-type="other" id="sec4"><title>Trainees&#x02019; views on digitisation and VSAQs</title><p>The opinion of psychiatry trainees was obtained via a presentation by the Chief Examiner, Dr Ian Hall, to the Psychiatric Trainees&#x02019; Committee. The Examinations Sub-Committee's Trainee Representative also sought feedback on the Psychiatric Trainees&#x02019; Committee collaborative platform, &#x02018;Workplace&#x02019;. The questions submitted to the College's webinar, &#x02018;MRCPsych Exam &#x02013; Changes to exam delivery this Autumn&#x02019;, attended by over a thousand psychiatry trainees and supervisors, were also reviewed in summarising concerns with regards to the digitisation of the theory examinations.</p><p>Psychiatry trainees raised several concerns with regards to the digitisation of the theory examinations (<xref rid="tab02" ref-type="table">Table 2</xref>). In the context of sitting the examinations from home, a common theme was how technical issues, such as insufficient internet connectivity, would be resolved, what support would be available to assist with this, and how the College would ensure candidates were not disadvantaged as a result of technical issues. Trainees also expressed concerns as to how cheating would be identified, particularly the potential to &#x02018;trick&#x02019; proctoring technology, to prevent inflated examination marks disadvantaging other trainees. Similarly, they expressed concerns that trainees may be falsely accused of cheating if they write notes or look away from the screen. The concerns regarding cheating are in keeping with the published literature of both candidates&#x02019; and examination setters&#x02019; perceptions of online examinations.<sup><xref rid="ref12" ref-type="bibr">12</xref></sup> Trainees also noted that some trainees&#x02019; home environments may be unsuitable for sitting examinations, because of caring commitments or house-sharing arrangements. Trainees were also keen to understand how candidates with dyslexia and other specific learning needs would be accommodated. Furthermore, trainees expressed an expectation that examination fees would be reduced in the context of digital examinations.
<table-wrap position="float" id="tab02"><label>Table 2</label><caption><p>Common themes of trainees&#x02019; concerns and responses</p></caption><alternatives><graphic xlink:href="S2056469421000231_tab2" position="float"/><table frame="hsides" rules="groups"><col align="left" width="1*" span="1"/><col align="left" width="1*" span="1"/><thead><tr><th align="left" colspan="1" rowspan="1">Concern</th><th align="left" colspan="1" rowspan="1">Reponses</th></tr></thead><tbody><tr><td colspan="1" rowspan="1">Technical issues, e.g. internet connectivity</td><td colspan="1" rowspan="1">The College partners with third-party software providers who have both expertise and a track record in high-stakes online examination delivery. Trainees are encouraged to test the resilience of their internet and device in advance, using provided software. Software developers design software to account for brief interruptions, and protocols exist for more significant technical issues.</td></tr><tr><td colspan="1" rowspan="1">Cheating, proctoring and false accusations</td><td colspan="1" rowspan="1">All alerts from the artificial intelligence software proctoring are reviewed by a live proctor. Final decisions about cheating are made following rigorous review by the Examinations Sub-committee, and subject to the normal appeals process.</td></tr><tr><td colspan="1" rowspan="1">Unsuitable home environment</td><td colspan="1" rowspan="1">Candidates can choose any suitable workstation with reliable internet to take the examination, e.g. a family member's or friend's house, a work or university computer.</td></tr><tr><td colspan="1" rowspan="1">Examination should not be reduced to a &#x02018;spelling test&#x02019; in very short answer questions</td><td colspan="1" rowspan="1">Variations in answers and spelling mistakes will be accounted for, and examiners would review incorrect answers, including typos and spelling errors.</td></tr></tbody></table></alternatives></table-wrap></p><p>Despite the concerns raised, trainees generally appeared to agree with the prospect of the digitisation of the theory examinations, even outside the current context of COVID-19. However, many expressed a strong preference for these to be conducted in test centres to prevent technical issues or cheating, and to ensure candidates with home settings unsuitable for sitting examinations were not disadvantaged.</p><p>With regards to the introduction of VSAQs, the trainee response was generally positive. Trainees felt it addressed their request for a greater emphasis on the testing of core knowledge and that VSAQs were better at testing the application of knowledge than the current format. However strong concerns were raised with regards to the examinations not becoming a &#x02018;spelling test&#x02019;, and particularly that this may disadvantage candidates with dyslexia, other specific learning needs and international medical graduates. They noted that not all spelling errors are of equal clinical significance and where it is clear that a candidate's intended meaning is correct, that this should be accepted as a correct answer.</p></sec><sec sec-type="conclusions" id="sec5"><title>Conclusions and future directions</title><p>The digitisation of examinations is inevitable, and the pace of change has been rapid as a result of the COVID-19 pandemic. For the MRCPsych theory papers, this could bring several improvements in terms of examination delivery, such as improved convenience and access to the examination, and faster processing of results. However, it also brings opportunities for improving assessment. We hope that a careful, phased introduction of alternative question formats such as VSAQs will enable a more comprehensive sampling of the examination syllabus, a greater focus on core knowledge and promote deeper, more holistic and integrated learning strategies. We know that these issues are of importance to trainees and clinical educators alike.</p><p>Any change like this requires comprehensive evaluation and testing, and because this is a high-stakes postgraduate medical qualification, the UK General Medical Council will need to prospectively approve any changes.<sup><xref rid="ref21" ref-type="bibr">21</xref></sup> As mentioned above, before any partial introduction, we plan to pilot questions on trainees and conduct an extensive psychometric analysis of the results. This would include an equality analysis to assess the impact on differential attainment in protected groups. The successful delivery of such a change requires comprehensive stakeholder engagement, and none are more important that the doctors training in psychiatry who take the examination; we plan ongoing consultation with trainees. We must also ensure that our training programmes prepare candidates thoroughly, with supervisors and tutors being up to date with new assessment methodologies and the reasons for their introduction. There would be the potential for online learning platforms to assist trainees with the new style questions. Stakeholder feedback has been largely positive on the face validity of VSAQs, in promoting the acquisition of knowledge that will be useful in clinical practice, and so help deliver better healthcare for people with mental health problems.</p></sec></body><back><ack><title>Acknowledgements</title><p>We thank the trainees who contributed their views to this paper, both from the Psychiatric Trainees&#x02019; Committee and those who attended the webinar.</p></ack><notes id="nts11" notes-type="other"><title>About the authors</title><p><bold>Karl Scheeres</bold> is a lecturerat the Centre for Health Sciences Education at the University of Bristol, UK, and Chair of Standard Setting for MRCPsych theory papers at the Royal College of Psychiatrists, UK. <bold>Niruj Agrawal</bold> is Lead Consultant Neuropsychiatrist at St George's Hospital, UK, and an honorary senior lecturer at St George's, University of London, UK. He is also Lead for VSAQs for MRCPsych examinations at the Royal College of Psychiatrists, UK. <bold>Stephanie Ewen</bold> is a specialist registrar in psychiatry of intellectual disability at South London and Maudsley NHS Foundation Trust, UK, and the Trainee Representative on the Royal College of Psychiatrists Examinations Sub-Committee, UK. <bold>Ian Hall</bold> is a consultant psychiatrist for people with intellectual disabilities at East London NHS Foundation Trust, UK, and Chief Examiner at the Royal College of Psychiatrists, UK.</p></notes><notes id="nts1" notes-type="other"><title>Author contributions</title><p>We confirm that all authors meet all four ICMJE criteria for authorship. K.S., N.A. and I.H. conceived the article, K.S, N.A, S.E. and I.H. all contributed to the draft and final versions. K.S. reviewed and revised the article.</p></notes><sec sec-type="COI-statement" id="nts2"><title>Declaration of interest</title><p>All authors are members of the Examinations Sub-Committee at the Royal College of Psychiatrists, which sets the MRCPsych theory papers. This article represents their views rather than the view of the committee as a whole.</p></sec><ref-list id="reflist1"><title>References</title><ref id="ref1"><label>1</label><mixed-citation publication-type="journal" id="cite1"><string-name><surname>Epstein</surname>
<given-names>RM</given-names></string-name>. <article-title>Assessment in medical education</article-title>. <source>N Engl J Med</source>
<year>2007</year>; <volume>356</volume>(<issue>4</issue>): <fpage>387</fpage>&#x02013;96.<pub-id pub-id-type="pmid">17251535</pub-id></mixed-citation></ref><ref id="ref2"><label>2</label><mixed-citation publication-type="journal" id="cite2"><string-name><surname>Van Der Vleuten</surname>
<given-names>CP</given-names></string-name>. <article-title>The assessment of professional competence: developments, research and practical implications</article-title>. <source>Adv Health Sci Educ</source>
<year>1996</year>; <volume>1</volume>(<issue>1</issue>): <fpage>41</fpage>&#x02013;<lpage>67</lpage>.</mixed-citation></ref><ref id="ref3"><label>3</label><mixed-citation publication-type="journal" id="cite3"><string-name><surname>Tyrer</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Oyebode</surname>
<given-names>F</given-names></string-name>. <article-title>Why does the MRCPsych examination need to change?</article-title>
<source>Br J Psychiatry</source>
<year>2004</year>; <volume>184</volume>(<issue>3</issue>): <fpage>197</fpage>&#x02013;9.<pub-id pub-id-type="pmid">14990516</pub-id></mixed-citation></ref><ref id="ref4"><label>4</label><mixed-citation publication-type="book" id="cite4"><string-name><surname>Jolly</surname>
<given-names>B</given-names></string-name>. <part-title>Written assessment</part-title>. In <source>Understanding Medical Education: Evidence, Theory and Practice</source> (eds <string-name><given-names>T</given-names>
<surname>Swanwick</surname></string-name>, <string-name><given-names>K</given-names>
<surname>Forrest</surname></string-name>, <string-name><given-names>BC</given-names>
<surname>O'Brien</surname></string-name>): <fpage>255</fpage>&#x02013;77. <publisher-name>Wiley Blackwell</publisher-name>, <year>2014</year>.</mixed-citation></ref><ref id="ref5"><label>5</label><mixed-citation publication-type="journal" id="cite5"><string-name><surname>Shields</surname>
<given-names>GS</given-names></string-name>. <article-title>Raising the standard: it's time to review the MRCPsych examinations</article-title>. <source>BJPsych Bull</source>
<year>2015</year>; <volume>39</volume>(<issue>5</issue>): <fpage>262</fpage>.</mixed-citation></ref><ref id="ref6"><label>6</label><mixed-citation publication-type="journal" id="cite6"><string-name><surname>Watkins</surname>
<given-names>LV</given-names></string-name>. <article-title>Is the MRCPsych fit for purpose?</article-title>
<source>J Ment Health Train Educ Pract</source>
<year>2017</year>; <volume>12</volume>(<issue>5</issue>): <fpage>331</fpage>&#x02013;6.</mixed-citation></ref><ref id="ref7"><label>7</label><mixed-citation publication-type="journal" id="cite7"><string-name><surname>Schuwirth</surname>
<given-names>LW</given-names></string-name>, <string-name><surname>Van der Vleuten</surname>
<given-names>CP</given-names></string-name>, <string-name><surname>Donkers</surname>
<given-names>HH</given-names></string-name>. <article-title>A closer look at cueing effects in multiple-choice questions</article-title>. <source>Med Educ</source>
<year>1996</year>; <volume>30</volume>(<issue>1</issue>): <fpage>44</fpage>&#x02013;9.<pub-id pub-id-type="pmid">8736188</pub-id></mixed-citation></ref><ref id="ref8"><label>8</label><mixed-citation publication-type="journal" id="cite8"><string-name><surname>Wood</surname>
<given-names>T</given-names></string-name>. <article-title>Assessment not only drives learning, it may also help learning</article-title>. <source>Med Educ</source>
<year>2009</year>; <volume>43</volume>: <fpage>5</fpage>&#x02013;<lpage>6</lpage>.<pub-id pub-id-type="pmid">19140992</pub-id></mixed-citation></ref><ref id="ref9"><label>9</label><mixed-citation publication-type="journal" id="cite9"><string-name><surname>Surry</surname>
<given-names>LT</given-names></string-name>, <string-name><surname>Torre</surname>
<given-names>D</given-names></string-name>, <string-name><surname>Durning</surname>
<given-names>SJ</given-names></string-name>. <article-title>Exploring examinee behaviours as validity evidence for multiple-choice question examinations</article-title>. <source>Med Educ</source>
<year>2017</year>; <volume>51</volume>(<issue>10</issue>): <fpage>1075</fpage>&#x02013;85.<pub-id pub-id-type="pmid">28758233</pub-id></mixed-citation></ref><ref id="ref10"><label>10</label><mixed-citation publication-type="journal" id="cite10"><string-name><surname>Al-Kadri</surname>
<given-names>HM</given-names></string-name>, <string-name><surname>Al-Moamary</surname>
<given-names>MS</given-names></string-name>, <string-name><surname>Roberts</surname>
<given-names>C</given-names></string-name>, <string-name><surname>van der Vleuten</surname>
<given-names>CP</given-names></string-name>. <article-title>Exploring assessment factors contributing to students&#x02019; study strategies: literature review</article-title>. <source>Med Teach</source>
<year>2012</year>; <volume>34</volume>(<issue>suppl 1</issue>): <fpage>42</fpage>&#x02013;<lpage>50</lpage>.</mixed-citation></ref><ref id="ref11"><label>11</label><mixed-citation publication-type="journal" id="cite11"><string-name><surname>Acosta</surname>
<given-names>C</given-names></string-name>, <string-name><surname>Ashraph</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Bainton</surname>
<given-names>J</given-names></string-name>, <string-name><surname>Baird</surname>
<given-names>D</given-names></string-name>, <string-name><surname>Banham</surname>
<given-names>L</given-names></string-name>, <string-name><surname>Barnes</surname>
<given-names>A</given-names></string-name>, <etal/>
<article-title>Royal College examination fees surplus</article-title>. <source>Psychiatrist</source>
<year>2012</year>; <volume>36</volume>(<issue>7</issue>): <fpage>273</fpage>&#x02013;4.</mixed-citation></ref><ref id="ref12"><label>12</label><mixed-citation publication-type="journal" id="cite12"><string-name><surname>Butler-Henderson</surname>
<given-names>K</given-names></string-name>, <string-name><surname>Crawford</surname>
<given-names>J</given-names></string-name>. <article-title>A systematic review of online examinations: a pedagogical innovation for scalable authentication and integrity</article-title>. <source>Comput Educ</source>
<year>2020</year>; 159: <fpage>104024</fpage>.<pub-id pub-id-type="pmid">32982023</pub-id></mixed-citation></ref><ref id="ref13"><label>13</label><mixed-citation publication-type="journal" id="cite13"><string-name><surname>H&#x000fc;seyin</surname>
<given-names>&#x000d6;Z</given-names></string-name>, <string-name><surname>&#x000d6;zturan</surname>
<given-names>T</given-names></string-name>. <article-title>Computer-based and paper-based testing: does the test administration mode influence the reliability and validity of achievement tests?</article-title>
<source>J Lang Linguist Stud</source>
<year>2018</year>; <volume>14</volume>(<issue>1</issue>): <fpage>67</fpage>&#x02013;<lpage>85</lpage>.</mixed-citation></ref><ref id="ref14"><label>14</label><mixed-citation publication-type="journal" id="cite14"><string-name><surname>Stowell</surname>
<given-names>JR</given-names></string-name>, <string-name><surname>Bennett</surname>
<given-names>D</given-names></string-name>. <article-title>Effects of online testing on student exam performance and test anxiety</article-title>. <source>J Educ Comput Res</source>
<year>2010</year>; <volume>42</volume>(<issue>2</issue>): <fpage>161</fpage>&#x02013;71.</mixed-citation></ref><ref id="ref15"><label>15</label><mixed-citation publication-type="journal" id="cite15"><string-name><surname>Sam</surname>
<given-names>AH</given-names></string-name>, <string-name><surname>Hameed</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Harris</surname>
<given-names>J</given-names></string-name>, <string-name><surname>Meeran</surname>
<given-names>K</given-names></string-name>. <article-title>Validity of very short answer versus single best answer questions for undergraduate assessment</article-title>. <source>BMC Med Educ</source>
<year>2016</year>; <volume>16</volume>: <fpage>266</fpage>.<pub-id pub-id-type="pmid">27737661</pub-id></mixed-citation></ref><ref id="ref16"><label>16</label><mixed-citation publication-type="journal" id="cite16"><string-name><surname>Sam</surname>
<given-names>AH</given-names></string-name>, <string-name><surname>Field</surname>
<given-names>SM</given-names></string-name>, <string-name><surname>Collares</surname>
<given-names>CF</given-names></string-name>, <string-name><surname>van der Vleuten</surname>
<given-names>CP</given-names></string-name>, <string-name><surname>Wass</surname>
<given-names>VJ</given-names></string-name>, <string-name><surname>Melville</surname>
<given-names>C</given-names></string-name>, <etal/>
<article-title>Very-short-answer questions: reliability, discrimination and acceptability</article-title>. <source>Med Educ</source>
<year>2018</year>; <volume>52</volume>(<issue>4</issue>): <fpage>447</fpage>&#x02013;55.<pub-id pub-id-type="pmid">29388317</pub-id></mixed-citation></ref><ref id="ref17"><label>17</label><mixed-citation publication-type="journal" id="cite17"><string-name><surname>Sam</surname>
<given-names>AH</given-names></string-name>, <string-name><surname>Westacott</surname>
<given-names>R</given-names></string-name>, <string-name><surname>Gurnell</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Wilson</surname>
<given-names>R</given-names></string-name>, <string-name><surname>Meeran</surname>
<given-names>K</given-names></string-name>, <string-name><surname>Brown</surname>
<given-names>C</given-names></string-name>. <article-title>Comparing single-best-answer and very-short-answer questions for the assessment of applied medical knowledge in 20 UK medical schools: cross-sectional study</article-title>. <source>BMJ Open</source>
<year>2019</year>; <volume>9</volume>(<issue>9</issue>): <fpage>e032550</fpage>.</mixed-citation></ref><ref id="ref18"><label>18</label><mixed-citation publication-type="journal" id="cite18"><string-name><surname>Sam</surname>
<given-names>AH</given-names></string-name>, <string-name><surname>Fung</surname>
<given-names>CY</given-names></string-name>, <string-name><surname>Wilson</surname>
<given-names>RK</given-names></string-name>, <string-name><surname>Peleva</surname>
<given-names>E</given-names></string-name>, <string-name><surname>Kluth</surname>
<given-names>DC</given-names></string-name>, <string-name><surname>Lupton</surname>
<given-names>M</given-names></string-name>, <etal/>
<article-title>Using prescribing very short answer questions to identify sources of medication errors: a prospective study in two UK medical schools</article-title>. <source>BMJ Open</source>
<year>2019</year>; <volume>9</volume>(<issue>7</issue>): <fpage>e028863</fpage>.</mixed-citation></ref><ref id="ref19"><label>19</label><mixed-citation publication-type="journal" id="cite19"><string-name><surname>Sam</surname>
<given-names>AH</given-names></string-name>, <string-name><surname>Peleva</surname>
<given-names>E</given-names></string-name>, <string-name><surname>Fung</surname>
<given-names>CY</given-names></string-name>, <string-name><surname>Cohen</surname>
<given-names>N</given-names></string-name>, <string-name><surname>Benbow</surname>
<given-names>EW</given-names></string-name>, <string-name><surname>Meeran</surname>
<given-names>K</given-names></string-name>. <article-title>Very short answer questions: a novel approach to summative assessments in pathology</article-title>. <source>Adv Med Educ Pract</source>
<year>2019</year>; <volume>10</volume>: <fpage>943</fpage>.<pub-id pub-id-type="pmid">31807109</pub-id></mixed-citation></ref><ref id="ref20"><label>20</label><mixed-citation publication-type="journal" id="cite20"><string-name><surname>Phillips</surname>
<given-names>G</given-names></string-name>, <string-name><surname>Jones</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Dagg</surname>
<given-names>K</given-names></string-name>. <article-title>Restarting training and examinations in the era of COVID-19: a perspective from the Federation of Royal Colleges of Physicians UK</article-title>. <source>Clin Med</source>
<year>2020</year>; <volume>20</volume>(<issue>6</issue>): <fpage>e248</fpage>.</mixed-citation></ref><ref id="ref21"><label>21</label><mixed-citation publication-type="other" id="cite21"><collab>General Medical Council</collab>. <italic toggle="yes">Designing and Maintaining Postgraduate Assessment Programmes.</italic> General Medical Council, 2017 (<uri xlink:href="https://www.gmc-uk.org/-/media/documents/designing-and-maintaining-postgraduate-assessment-programmes-0517_pdf-70434370.pdf">https://www.gmc-uk.org/-/media/documents/designing-and-maintaining-postgraduate-assessment-programmes-0517_pdf-70434370.pdf</uri>).</mixed-citation></ref></ref-list></back></article>